{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No livro é bem detalhado a implementação em R.\n",
    "\n",
    "Entretanto, para a implementação em Python de árvores para previsão, existem vários vídeos e artigos.\n",
    "\n",
    "Por exemplo, indicação de vídeo para introduzir o assunto, recomendo:\n",
    "\n",
    "1. https://youtu.be/z3ZnOW-S550\n",
    "\n",
    "2. https://www.youtube.com/watch?v=RRd2wzMRpOc\n",
    "\n",
    "São duas implementações bem simples e bacanas para começar, a primeira com o XGBoost e a segunda com RandomForest.\n",
    "\n",
    "Existe uma competição no Kaggle chamada Enefit, recomendo esse notebook:\n",
    "\n",
    "1. https://www.kaggle.com/code/rafiko1/enefit-xgboost-starter\n",
    "\n",
    "Existe outra competição chamada Rossmann, com mais alguns notebooks, como estes:\n",
    "\n",
    "1. https://www.kaggle.com/code/sridharstreaks/gbms-with-xgboost-intution-model-building#End-of-XGBoost-Intuition (bem detalhado).\n",
    "2. https://www.kaggle.com/code/kunwarakash/rossmann-store-sales-forecast-ml-model-by-xgboost\n",
    "3. https://www.kaggle.com/code/manishleo10/gradient-boosting-machines-gbms-with-xgboost#Problem-Statement\n",
    "\n",
    "Extra:\n",
    "\n",
    "XGB Parameter Tuning: https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning#A-Guide-on-XGBoost-hyperparameters-tuning"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
